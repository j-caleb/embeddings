{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: This is a far cry from what this will eventually be. As of now, this is just a very quick overview.\n",
    "\n",
    "The vectors used in this tutorial can be downloaded here: https://bit.ly/2XUcNWU\n",
    "\n",
    "The vectors were trained on 1 million MEDLINE abstracts (these are medical scientific abstracts). The dimensionality of the vectors is 500 and I used seeds=20 for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from random_indexing.query import QueryVectors\n",
    "from utils import text_utils\n",
    "from utils import vector_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"F:\\\\github_projects\\\\data\\\\embeddings\\\\medline_sentences\\\\ri_demo\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ri = QueryVectors(path + 'ri/term_index_ri')\n",
    "drri = QueryVectors(path + 'drri/term_index_drri')\n",
    "trri = QueryVectors(path + 'trri/term_index_trri')\n",
    "window = QueryVectors(path + 'window/term_index_window')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is random projection?\n",
    "\n",
    "I will be using the phrase 'random projection' a lot. So what is random projection? There is a lot of very interesting mathematical theory behind it, but it is very very simple. For our purposes, you select the desired dimensionality (dim) and the number of seeds. For a given term or document, you initialize its vector to size dim. You then select N elements of the vector where N is determined by seeds and randomly flip these elements to +1 or -1. Congrats! You have just randomly projected!\n",
    "\n",
    "This works because when you randomly project using this approach the randomly projected vectors are near orthogonal to each other. In other words, you have a unique identifier for a word or document in the lower dimensional space.\n",
    "\n",
    "For demonstration purposes, this is what a vector looks like when initialized with random projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0. -1.  0.\n",
      "  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -1.  0.  0.  0.\n",
      "  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -1.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.\n",
      "  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -1.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "vectors = vector_utils.initialize_vectors_random_projection(['fish'], dim=500, seeds=20)\n",
    "print(vectors['fish'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example queries with random indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Indexing is the vanilla version that was originally proposed as an alternative to LSA. Random Indexing is an incredibly fast method for generating vectors and is highly parallelizable. Vanilla Random Indexing uses the document as context and then uses random projection to map each document to a fixed dimensional space (500 dimensions in this case). Random projection more or less gives each document a unique ID. For training, for each term in a document you add the document vector to the term vector.\n",
    "\n",
    "The results are 'ok.' To be fair, 1 million documents is not a lot and I also have not implemented term weighting at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mother', 1.0),\n",
       " ('father', 0.25328775133169823),\n",
       " ('maternal', 0.22938290392806948),\n",
       " ('mothers', 0.2206636706180367),\n",
       " ('infant', 0.19130721074871948),\n",
       " ('alternated', 0.18989466060845117),\n",
       " ('ppar-Î±', 0.18852798235854762),\n",
       " ('ln229', 0.1865784950289182),\n",
       " ('metapopulations', 0.18180235370409403),\n",
       " ('mgl', 0.178919612315935)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ri.get_similar('mother')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ulcerative', 0.8587647045774129),\n",
       " ('colitis', 0.8587647045774129),\n",
       " ('uc', 0.2458510566665434),\n",
       " ('crohn', 0.23734590798881516),\n",
       " ('dss', 0.19987876825718698),\n",
       " ('interfere', 0.17927755192195305),\n",
       " ('brew', 0.1753638280767027),\n",
       " ('8-oh-dg', 0.17291678480842132),\n",
       " ('cbr', 0.1666171450700007),\n",
       " ('ibd', 0.16650605213170122)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ri.get_similar('ulcerative colitis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example queries with random indexing with sliding window\n",
    "\n",
    "It may not be advantageous to always treat the entire document as context as we did previously. For example, a given document may have different topics. Here I use a variant of Random Indexing that uses a sliding window approach. I trained this particular model with a window of 5.\n",
    "\n",
    "Let's look at the context for the following sentence: Fish oil has been shown to reduce blood pressure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fish', ['oil', 'reduce', 'blood', 'pressure.']]\n",
      "['oil', ['Fish', 'reduce', 'blood', 'pressure.']]\n",
      "['reduce', ['Fish', 'oil', 'blood', 'pressure.']]\n",
      "['blood', ['Fish', 'oil', 'reduce', 'pressure.']]\n",
      "['pressure.', ['Fish', 'oil', 'reduce', 'blood']]\n"
     ]
    }
   ],
   "source": [
    "sent = 'Fish oil has been shown to reduce blood pressure.'\n",
    "\n",
    "contexts = text_utils.create_context_training(sent, 5, set(sent.split()))\n",
    "\n",
    "for context in contexts:\n",
    "    print(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In training, each term is mapped to a lower dimensional space using random projection. For each document, you break the document into a set of contexts as above. For ['Fish', ['oil', 'reduce', 'blood', 'pressure.']], 'Fish' is the target term. You obtain the vector for 'Fish', and then add the vectors for ['oil', 'reduce', 'blood', 'pressure.'] to it.\n",
    "\n",
    "Below is the results to Random Indexing with the same queries. Looks much better!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mother', 1.0),\n",
       " ('child', 0.7288195466566987),\n",
       " ('dyads', 0.7258266563285336),\n",
       " ('parent', 0.7247515408407812),\n",
       " ('infant', 0.7116490350809898),\n",
       " ('maternal', 0.6991020961555843),\n",
       " ('baby', 0.6576233255853627),\n",
       " ('mothers', 0.6455671590380575),\n",
       " ('father', 0.6454699859477869),\n",
       " ('parental', 0.6447839830193891)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window.get_similar('mother')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ulcerative', 0.8930706544287557),\n",
       " ('colitis', 0.8930706544287557),\n",
       " ('uc', 0.7707548551366463),\n",
       " ('crohn', 0.7365325448157829),\n",
       " ('ileitis', 0.7200394152702355),\n",
       " ('pancolitis', 0.6776322028485896),\n",
       " ('ibd', 0.6659753898580144),\n",
       " ('fistulizing', 0.6397353252313589),\n",
       " ('dss', 0.6173235312895747),\n",
       " ('pseudomembranous', 0.6033841113219148)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window.get_similar('ulcerative colitis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples of Reflective Random Indexing\n",
    "\n",
    "Around 2010 it was discovered that you can do multiple iterations of training. This was dubbed Reflective Random Indexing. We will look at two examples: document-based Reflective Random Indexing (DRRI) and term-based Reflective Random Indexing (TRRI). It should be noted that these approaches generate document vectors, but I am currently not saving them. I will need to include some sort of approximate nearest neighbors search to make these usable.\n",
    "\n",
    "TRRI and DRRI are very similar and the difference really boils down to the order of operations during training. During TRRI, you perform random projection on the terms and then add the terms to the document vector. Next you perform the reflective step where you add the document vector to the terms that are in the document. DRRI is essentially the same but you begin by applying random projection to the document vectors.\n",
    "\n",
    "Reflective Random Indexing opened up the potential to apply these approaches in very creative ways. For example, you can associate text with labels, text with authors, authors with citations, and so forth. Unfortunately, you are limited in how much you can reflect as you eventually will end up with a mud puddle.\n",
    "\n",
    "Below are the same queries performed using TRRI and DRRI.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mother', 1.0),\n",
       " ('mothers', 0.7366709382283277),\n",
       " ('father', 0.7327814148389312),\n",
       " ('maternal', 0.7209406519691841),\n",
       " ('infant', 0.7007631444239568),\n",
       " ('child', 0.6776361501810731),\n",
       " ('dyads', 0.6702282412682318),\n",
       " ('baby', 0.640874762678684),\n",
       " ('neurodevelopment', 0.6278331319647544),\n",
       " ('toddler', 0.6219275004574695)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trri.get_similar('mother')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mother', 1.0),\n",
       " ('father', 0.9688162255507828),\n",
       " ('infant', 0.9677965946881427),\n",
       " ('maternal', 0.9667039576985549),\n",
       " ('mothers', 0.9658348463525763),\n",
       " ('baby', 0.9603432202002335),\n",
       " ('prenatal', 0.9565578854048025),\n",
       " ('infancy', 0.9558384543571197),\n",
       " ('born', 0.9554195311172776),\n",
       " ('dyads', 0.9521744465013378)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drri.get_similar('mother')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ulcerative', 0.9720778576004048),\n",
       " ('colitis', 0.9720778576004047),\n",
       " ('crohn', 0.8131168553627316),\n",
       " ('pancolitis', 0.8089453682144533),\n",
       " ('ibd', 0.7333352071881086),\n",
       " ('uc', 0.7179428268740302),\n",
       " ('aminosalicylates', 0.7058131722863821),\n",
       " ('ibds', 0.695012002047562),\n",
       " ('disease', 0.6869420642449156),\n",
       " ('bowel', 0.6797990237865235)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trri.get_similar('ulcerative colitis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('colitis', 0.9933332772974606),\n",
       " ('ulcerative', 0.9933332772974606),\n",
       " ('uc', 0.9604458048226887),\n",
       " ('crohn', 0.9581159673318018),\n",
       " ('ibds', 0.9504978128969214),\n",
       " ('ibd', 0.9492115569155353),\n",
       " ('pancolitis', 0.9480324919325203),\n",
       " ('dss', 0.9427591135066176),\n",
       " ('colonic', 0.9427114578695646),\n",
       " ('ileitis', 0.9390434791628233)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drri.get_similar('ulcerative colitis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
